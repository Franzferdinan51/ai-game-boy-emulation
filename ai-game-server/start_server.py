#!/usr/bin/env python3
"""
Easy startup script for AI Game Server with provider detection
"""
import os
import sys
import logging
import json
from pathlib import Path

# Add the src directory to Python path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

from backend.ai_apis.ai_provider_manager import AIProviderManager
from backend.server import app, logger

def print_banner():
    """Print welcome banner"""
    banner = """
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘                AI Game Server - Startup Script                â•‘
    â•‘          Pokemon Game Automation with Multiple AI Providers   â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """
    print(banner)

def check_environment():
    """Check environment configuration"""
    print("\nğŸ” Checking environment configuration...")

    env_vars = {
        'GEMINI_API_KEY': 'Google Gemini (Free tier available)',
        'OPENROUTER_API_KEY': 'OpenRouter (Paid)',
        'OPENAI_API_KEY': 'OpenAI API (Paid)',
        'OPENAI_ENDPOINT': 'OpenAI-compatible endpoint (e.g., LM Studio)',
        'NVIDIA_API_KEY': 'NVIDIA NIM (Paid)'
    }

    configured = []
    missing = []

    for var, description in env_vars.items():
        if os.environ.get(var):
            configured.append(f"âœ“ {description}")
        else:
            missing.append(f"âœ— {description}")

    if configured:
        print("\nğŸŸ¢ Configured providers:")
        for item in configured:
            print(f"   {item}")

    if missing:
        print("\nğŸ”´ Missing providers:")
        for item in missing:
            print(f"   {item}")

    return len(configured) > 0

def check_local_providers():
    """Check for local AI providers"""
    print("\nğŸ” Checking local AI providers...")

    local_providers = [
        {
            'name': 'LM Studio',
            'url': 'http://localhost:1234/v1',
            'description': 'Local model server (http://localhost:1234/v1)'
        },
        {
            'name': 'Ollama',
            'url': 'http://localhost:11434/api/tags',
            'description': 'Local model server (http://localhost:11434)'
        }
    ]

    available_local = []

    for provider in local_providers:
        try:
            import requests
            response = requests.get(provider['url'], timeout=5)
            if response.status_code == 200:
                available_local.append(provider)
                print(f"âœ“ {provider['name']} is running")
            else:
                print(f"âœ— {provider['name']} not responding")
        except Exception:
            print(f"âœ— {provider['name']} not running")

    return available_local

def setup_local_provider():
    """Setup environment for local provider"""
    print("\nğŸ”§ Setting up local provider configuration...")

    # Check if LM Studio is available
    try:
        import requests
        response = requests.get('http://localhost:1234/v1/models', timeout=5)
        if response.status_code == 200:
            os.environ['OPENAI_API_KEY'] = 'not-needed'
            os.environ['OPENAI_ENDPOINT'] = 'http://localhost:1234/v1'
            os.environ['OPENAI_MODEL'] = 'local-model'
            print("âœ“ LM Studio detected and configured")
            return True
    except:
        pass

    # Check if Ollama is available
    try:
        import requests
        response = requests.get('http://localhost:11434/api/tags', timeout=5)
        if response.status_code == 200:
            os.environ['OPENAI_API_KEY'] = 'not-needed'
            os.environ['OPENAI_ENDPOINT'] = 'http://localhost:11434/v1'
            os.environ['OPENAI_MODEL'] = 'llava'  # LLaVA for vision
            print("âœ“ Ollama detected and configured")
            return True
    except:
        pass

    return False

def test_providers():
    """Test all available providers"""
    print("\nğŸ§ª Testing AI providers...")

    try:
        manager = AIProviderManager()
        status = manager.get_provider_status()
        available = manager.get_available_providers()

        print(f"\nğŸ“Š Provider Status:")
        for provider_name, provider_info in status.items():
            status_icon = "ğŸŸ¢" if provider_info['available'] else "ğŸ”´"
            print(f"   {status_icon} {provider_name}: {provider_info['status'].upper()}")
            if provider_info['error']:
                print(f"      Error: {provider_info['error']}")

        print(f"\nâœ… Available providers: {len(available)}")
        for provider in available:
            print(f"   â€¢ {provider}")

        return len(available) > 0

    except Exception as e:
        print(f"âŒ Error testing providers: {e}")
        return False

def show_usage():
    """Show usage instructions"""
    print("\nğŸ“– Usage Instructions:")
    print("""
    1. API Endpoints:
       â€¢ GET  /api/status           - Get server status
       â€¢ GET  /api/providers/status - Get provider status
       â€¢ POST /api/ai-action        - Get AI action
       â€¢ POST /api/chat             - Chat with AI
       â€¢ GET  /api/screen           - Get game screen
       â€¢ GET  /api/stream           - Screen stream

    2. Web Interface:
       â€¢ Open http://localhost:5000 in your browser

    3. Example API calls:
       curl -X POST http://localhost:5000/api/ai-action \\
            -H "Content-Type: application/json" \\
            -d '{"goal": "Navigate through the game"}'

    4. Configuration:
       â€¢ Edit .env file to configure API keys
       â€¢ See AI_PROVIDER_SETUP.md for detailed setup
    """)

def show_provider_help():
    """Show help for setting up providers"""
    print("\nğŸ› ï¸  Provider Setup Help:")
    print("""
    ğŸŒŸ Google Gemini (Free):
       â€¢ Visit: https://makersuite.google.com/app/apikey
       â€¢ Get free API key
       â€¢ Set: GEMINI_API_KEY=your_key_here

    ğŸŒ OpenRouter (Paid):
       â€¢ Visit: https://openrouter.ai/keys
       â€¢ Deposit funds and get API key
       â€¢ Set: OPENROUTER_API_KEY=your_key_here

    ğŸ  Local Models (LM Studio/Ollama):
       â€¢ LM Studio: Download from https://lmstudio.ai/
       â€¢ Ollama: Download from https://ollama.ai/
       â€¢ Set: OPENAI_ENDPOINT=http://localhost:1234/v1
       â€¢ Set: OPENAI_API_KEY=not-needed

    ğŸ’¡ Quick Start:
       â€¢ Install LM Studio and download a vision model
       â€¢ Start LM Studio server on port 1234
       â€¢ Run this script again
    """)

def main():
    """Main startup function"""
    print_banner()

    # Check if running in right directory
    if not Path('.env.example').exists():
        print("âŒ Error: Please run this script from the ai-game-server directory")
        sys.exit(1)

    # Check environment
    has_env_config = check_environment()

    # Check local providers
    local_providers = check_local_providers()

    # Setup local provider if no cloud providers are configured
    if not has_env_config and not local_providers:
        print("\nğŸ”„ No providers configured. Attempting to setup local provider...")
        if setup_local_provider():
            print("âœ… Local provider configured successfully!")
        else:
            print("âŒ Could not detect any local AI providers.")
            show_provider_help()
            return

    # Test providers
    has_working_providers = test_providers()

    # Show server information
    print("\nğŸš€ Starting AI Game Server...")
    print(f"   ğŸ“ Server will run on: http://localhost:5000")
    print(f"   ğŸ“Š Status page: http://localhost:5000/api/status")
    print(f"   ğŸ”§ Provider status: http://localhost:5000/api/providers/status")

    if has_working_providers:
        print("   âœ… AI features are available!")
    else:
        print("   âš ï¸  No AI providers available - manual actions only")

    # Show usage
    show_usage()

    print("\n" + "="*60)
    print("ğŸ® Press Ctrl+C to stop the server")
    print("="*60 + "\n")

    # Start the server
    try:
        app.run(host='0.0.0.0', port=5000, debug=True)
    except KeyboardInterrupt:
        print("\nğŸ›‘ Server stopped by user")
    except Exception as e:
        print(f"\nâŒ Server error: {e}")

if __name__ == "__main__":
    main()